{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "plain-interval",
   "metadata": {},
   "source": [
    "##### 개와 고양이 인식하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-thriller",
   "metadata": {},
   "source": [
    "#####  데이터 구성\n",
    "\n",
    "- 총 25000(개 12500, 고양이 12500)개로 구성된 이미지 셋\n",
    "- 칼라 이미지 ,이미지의 크기는 다름\n",
    "- 미리 train , testm validataion으로 분리된 파일을 압축해둠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-trunk",
   "metadata": {},
   "source": [
    "#### 1. 압축을 풀어 폴더에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabulous-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,os.path, shutil, zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "divine-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 압축 파일명\n",
    "local_zip =\"./data/dogs-vs-cats.zip\"\n",
    "# 압축을 풀 파일을 읽어온다\n",
    "zip_ref = zipfile.ZipFile(local_zip,\"r\")\n",
    "# 압축 풀기\n",
    "zip_ref.extractall(\"./data\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personal-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 압축 파일명\n",
    "local_zip =\"./data/test1.zip\"\n",
    "# 압축을 풀 파일을 읽어온다\n",
    "zip_ref = zipfile.ZipFile(local_zip,\"r\")\n",
    "# 압축 풀기\n",
    "zip_ref.extractall(\"./data\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technical-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 압축 파일명\n",
    "local_zip =\"./data/train.zip\"\n",
    "# 압축을 풀 파일을 읽어온다\n",
    "zip_ref = zipfile.ZipFile(local_zip,\"r\")\n",
    "# 압축 풀기\n",
    "zip_ref.extractall(\"./data\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-reminder",
   "metadata": {},
   "source": [
    "/data/dogs_and_cats_small : 일부 데이터가 들어갈 메인 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/train : 훈련 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/train/dogs : 훈련 개 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/train/cats : 훈련 고양이 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/test : 테스트 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/test/dogs : 테스트 개 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/test/cats : 테스트 고양이 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/validation : 검증 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/validation/dogs : 검증 개 데이터가 들어갈 폴더\n",
    "\n",
    "/data/dogs_and_cats_small/validation/cats : 검증 고양이 데이터가 들어갈 폴더\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perfect-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 폴더를 생성\n",
    "# 훈련 데이터가 들어있는 폴더\n",
    "original_dataset_dir = \"./data/train\"\n",
    "# 일부 데이터가 들어갈 폴더 생성\n",
    "base_dir =\"./data/dogs_and_cats_small\"\n",
    "base_dir1 =\"./data/dogs_and_cats_small/train\"\n",
    "base_dir2 =\"./data/dogs_and_cats_small/train/dogs\"\n",
    "base_dir3 =\"./data/dogs_and_cats_small/train/cats\"\n",
    "base_dir4 =\"./data/dogs_and_cats_small/test\"\n",
    "base_dir5 =\"./data/dogs_and_cats_small/test/cats\"\n",
    "base_dir6 =\"./data/dogs_and_cats_small/test/dogs\"\n",
    "base_dir7 =\"./data/dogs_and_cats_small/validation\"\n",
    "base_dir8 =\"./data/dogs_and_cats_small/validation/dogs\"\n",
    "base_dir9 =\"./data/dogs_and_cats_small/validation/cats\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "if not os.path.exists(base_dir1):\n",
    "    os.mkdir(base_dir1)\n",
    "\n",
    "if not os.path.exists(base_dir2):\n",
    "    os.mkdir(base_dir2)\n",
    "\n",
    "if not os.path.exists(base_dir3):\n",
    "    os.mkdir(base_dir3)\n",
    "\n",
    "if not os.path.exists(base_dir4):\n",
    "    os.mkdir(base_dir4)\n",
    "\n",
    "if not os.path.exists(base_dir5):\n",
    "    os.mkdir(base_dir5)\n",
    "\n",
    "if not os.path.exists(base_dir6):\n",
    "    os.mkdir(base_dir6)\n",
    "\n",
    "if not os.path.exists(base_dir7):\n",
    "    os.mkdir(base_dir7)\n",
    "\n",
    "if not os.path.exists(base_dir8):\n",
    "    os.mkdir(base_dir8)\n",
    "\n",
    "if not os.path.exists(base_dir9):\n",
    "    os.mkdir(base_dir9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-canadian",
   "metadata": {},
   "source": [
    "#####  생성된 폴더로 각각 이미지들을 복사\n",
    "- 훈련 고양이 이미지 폴더 : 1000개 \n",
    "- 훈련 개 이미지 폴더 : 1000개 \n",
    "- 테스트 고양이 이미지 폴더 : 1000개\n",
    "- 테스트 개 이미지 폴더 : 1000개 \n",
    "- 검증 고양이 이미지 폴더 : 500개 \n",
    "- 검증 개 이미지 폴더 : 500개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brave-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 1000개의 고양이 이미지 파일을 train_cats_dir 폴더로 복사\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    # 원래 이미지가 있는 폴더와 파일명\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    # 복사할 위치의 폴더와 파일 명\n",
    "    dst = os.path.join(base_dir3,fname)\n",
    "    \n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hourly-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 1000개의 고양이 이미지 파일을 train_cats_dir 폴더로 복사\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    # 원래 이미지가 있는 폴더와 파일명\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    # 복사할 위치의 폴더와 파일 명\n",
    "    dst = os.path.join(base_dir2,fname)\n",
    "    \n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thousand-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 1000개의 고양이 이미지 파일을 train_cats_dir 폴더로 복사\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000,1500)]\n",
    "\n",
    "for fname in fnames:\n",
    "    # 원래 이미지가 있는 폴더와 파일명\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    # 복사할 위치의 폴더와 파일 명\n",
    "    dst = os.path.join(base_dir6,fname)\n",
    "    \n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alien-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 1000개의 고양이 이미지 파일을 train_cats_dir 폴더로 복사\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000,1500)]\n",
    "\n",
    "for fname in fnames:\n",
    "    # 원래 이미지가 있는 폴더와 파일명\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    # 복사할 위치의 폴더와 파일 명\n",
    "    dst = os.path.join(base_dir5,fname)\n",
    "    \n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disabled-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 1000개의 고양이 이미지 파일을 train_cats_dir 폴더로 복사\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1500,2000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    # 원래 이미지가 있는 폴더와 파일명\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    # 복사할 위치의 폴더와 파일 명\n",
    "    dst = os.path.join(base_dir9,fname)\n",
    "    \n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "diagnostic-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 1000개의 고양이 이미지 파일을 train_cats_dir 폴더로 복사\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1500,2000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    # 원래 이미지가 있는 폴더와 파일명\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    # 복사할 위치의 폴더와 파일 명\n",
    "    dst = os.path.join(base_dir8,fname)\n",
    "    \n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "guilty-dealer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 개 데이터 수:1000\n",
      "훈련 고양이 데이터 수:1000\n",
      "테스트 개 데이터 수:500\n",
      "테스트 고양이 데이터 수:500\n",
      "검증 개 데이터 수:500\n",
      "검증 고양이 데이터 수:500\n"
     ]
    }
   ],
   "source": [
    "# 복사한 파일의 수 확인\n",
    "# listdir() : 해당 폴더에 있는 파일을 가져온다\n",
    "print(\"훈련 개 데이터 수:{}\".format(len(os.listdir(base_dir2))))\n",
    "print(\"훈련 고양이 데이터 수:{}\".format(len(os.listdir(base_dir3))))\n",
    "print(\"테스트 개 데이터 수:{}\".format(len(os.listdir(base_dir6))))\n",
    "print(\"테스트 고양이 데이터 수:{}\".format(len(os.listdir(base_dir5))))\n",
    "print(\"검증 개 데이터 수:{}\".format(len(os.listdir(base_dir8))))\n",
    "print(\"검증 고양이 데이터 수:{}\".format(len(os.listdir(base_dir9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-formula",
   "metadata": {},
   "source": [
    "##### 이미지 전처리\n",
    "- 이미지를 같은 크기로 만들어 주어야 함\n",
    "- 0~255 범위의 픽셀값들을 0-1 사이 범위의 값으로 변환 -> 분산 감소\n",
    "- 라벨링\n",
    "- ImageDataGenerator() 함수를 사용해서 처리\n",
    "    - 이미지 전처리\n",
    "    - 증식\n",
    "    - 이미지를 부분 개수만큼 반복해서 처리(batch 처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggregate-senate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 픽셀값을 0-1 사이로 변환\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow_from_directory(폴더명, 이미지 크기, 한번에 변환할 이미지 수, 라벨링 모드)\n",
    "train_generator = train_gen.flow_from_directory(base_dir1,\n",
    "                                              target_size=(150,150),\n",
    "                                              batch_size=20,\n",
    "                                               # 다중 분류 : categorical\n",
    "                                               # 라벨 번호는 0부터 시작\n",
    "                                               # 폴더명의 알파벳 순으로 할당\n",
    "                                              class_mode=\"binary\") \n",
    "test_generator = test_gen.flow_from_directory(base_dir4,\n",
    "                                              target_size=(150,150),\n",
    "                                              batch_size=20,\n",
    "                                               # 다중 분류 : categorical\n",
    "                                               # 라벨 번호는 0부터 시작\n",
    "                                               # 폴더명의 알파벳 순으로 할당\n",
    "                                              class_mode=\"binary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unusual-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "#라벨링 결과 확인\n",
    "print(train_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-lightning",
   "metadata": {},
   "source": [
    "##### 초기화를 위한 seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collected-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "possible-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 180000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               92160512  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 92,161,921\n",
      "Trainable params: 92,161,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 입력층 (CNN층)\n",
    "# filters : 필터의 수, 출력의 수 (출력되는 이미지의 개수)\n",
    "# kernel_size : 필터의 크기 (3,3) (5,5), (7,7)\n",
    "# input_shape : 입력데이터의 크기 (2차원 이상인 경우에 사용)\n",
    "# padding : 컨벌루션 연산때문에 작아지는 이미지 크기를 유지할 것인 여부\n",
    "# same : 항상 같은 크기로 이미지를 유지해준다.  - padding\n",
    "# valid : 컬벌루션으로 줄어든 상태를 그대로 유지\n",
    "model.add(Conv2D(filters = 32 ,\n",
    "                     kernel_size = (3,3) , \n",
    "                     input_shape = (150,150,3),\n",
    "                     padding = \"same\" , \n",
    "                     activation = \"relu\"))\n",
    "# maxpooling2d -> ex)2,2 라면 가로 2 세로 2 로 필터를 추출\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# 은닉층에 넣기 전에 이전 데이터들을 1차원으로 변환\n",
    "model.add(Flatten())\n",
    "\n",
    "#은닉층\n",
    "model.add(Dense(units = 512, activation = \"relu\"))\n",
    "\n",
    "# 출력층\n",
    "model.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "effective-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer -> 최적화 도구(씨맥감독)\n",
    "# metrics -> 평가도구\n",
    "# 평가 도구에선 adam이 값이 제일 잘나옴\n",
    "# acc -> 정확도(찍어줌)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "drawn-monkey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-ff2bca46215c>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 77s 767ms/step - loss: 2.0822 - acc: 0.5715 - val_loss: 0.6371 - val_acc: 0.6230\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 71s 713ms/step - loss: 0.4791 - acc: 0.7840 - val_loss: 0.6901 - val_acc: 0.6340\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s 685ms/step - loss: 0.2409 - acc: 0.9200 - val_loss: 0.7403 - val_acc: 0.6570\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.1206 - acc: 0.9675 - val_loss: 0.7843 - val_acc: 0.6900\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s 689ms/step - loss: 0.0702 - acc: 0.9830 - val_loss: 0.9352 - val_acc: 0.6800\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s 685ms/step - loss: 0.0460 - acc: 0.9935 - val_loss: 0.9589 - val_acc: 0.6830\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.0268 - acc: 0.9965 - val_loss: 0.9555 - val_acc: 0.6840\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.0225 - acc: 0.9965 - val_loss: 1.1168 - val_acc: 0.6980\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.0086 - acc: 0.9995 - val_loss: 1.2134 - val_acc: 0.6900\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.2764 - val_acc: 0.6910\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(generator = train_generator,\n",
    "                        # batch_size가 20으로 설정되어 있음\n",
    "                        # 전체 데이터를(2000) 다 읽어오려면 몇 번 돌아가야하는지 설정\n",
    "                       steps_per_epoch = 100,\n",
    "                       epochs = 10,\n",
    "                       validation_data = test_generator,\n",
    "                        # 전체 데이터(1000개)/batch_size\n",
    "                       validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-registration",
   "metadata": {},
   "source": [
    "#####  증식을 이용해서 적은 데이터 개수를 늘려서 과대적합을 피해보자\n",
    "- data augmentation : 이미지 데이터를 회전, 이동,확대/축소,뒤집기 등을 이용해서 데이터를 늘리는 작업\n",
    "- imageDataGenerator() 함수를 이용해서 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dense-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증식 설정\n",
    "train_dataGen = ImageDataGenerator(rescale=1.255,\n",
    "                            rotation_range=20,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode=\"nearest\")\n",
    "\n",
    "#test는 증식하지 않음\n",
    "test_dataGen = ImageDataGenerator(rescale=1.255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "enabling-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_dataGen.flow_from_directory(base_dir1,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode=\"binary\")\n",
    "\n",
    "test_generator = test_dataGen.flow_from_directory(base_dir4,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode=\"binary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dental-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 180000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               92160512  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 92,161,921\n",
      "Trainable params: 92,161,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "# 입력층 (CNN층)\n",
    "# filters : 필터의 수, 출력의 수 (출력되는 이미지의 개수)\n",
    "# kernel_size : 필터의 크기 (3,3) (5,5), (7,7)\n",
    "# input_shape : 입력데이터의 크기 (2차원 이상인 경우에 사용)\n",
    "# padding : 컨벌루션 연산때문에 작아지는 이미지 크기를 유지할 것인 여부\n",
    "# same : 항상 같은 크기로 이미지를 유지해준다.  - padding\n",
    "# valid : 컬벌루션으로 줄어든 상태를 그대로 유지\n",
    "model1.add(Conv2D(filters = 32 ,\n",
    "                     kernel_size = (3,3) , \n",
    "                     input_shape = (150,150,3),\n",
    "                     padding = \"same\" , \n",
    "                     activation = \"relu\"))\n",
    "# maxpooling2d -> ex)2,2 라면 가로 2 세로 2 로 필터를 추출\n",
    "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# 은닉층에 넣기 전에 이전 데이터들을 1차원으로 변환\n",
    "model1.add(Flatten())\n",
    "\n",
    "#은닉층\n",
    "model1.add(Dense(units = 512, activation = \"relu\"))\n",
    "\n",
    "# 출력층\n",
    "model1.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "guilty-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer -> 최적화 도구(씨맥감독)\n",
    "# metrics -> 평가도구\n",
    "# 평가 도구에선 adam이 값이 제일 잘나옴\n",
    "# acc -> 정확도(찍어줌)\n",
    "model1.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "naval-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 1.3202 - acc: 0.5785 - val_loss: 2.1501 - val_acc: 0.5560\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 66s 664ms/step - loss: 1.0863 - acc: 0.5985 - val_loss: 1.9240 - val_acc: 0.5770\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 69s 690ms/step - loss: 1.0311 - acc: 0.5820 - val_loss: 1.8332 - val_acc: 0.5860\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.9336 - acc: 0.5920 - val_loss: 1.8819 - val_acc: 0.5620\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.8781 - acc: 0.5940 - val_loss: 1.7144 - val_acc: 0.5890\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 68s 684ms/step - loss: 0.8195 - acc: 0.6170 - val_loss: 1.5593 - val_acc: 0.5770\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.8337 - acc: 0.6055 - val_loss: 1.6936 - val_acc: 0.5720\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 0.7529 - acc: 0.6050 - val_loss: 1.4497 - val_acc: 0.5790\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 71s 708ms/step - loss: 0.7737 - acc: 0.6135 - val_loss: 1.4044 - val_acc: 0.5880\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 69s 689ms/step - loss: 0.7275 - acc: 0.6155 - val_loss: 1.4088 - val_acc: 0.5980\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.7432 - acc: 0.6145 - val_loss: 1.3267 - val_acc: 0.5900\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.7198 - acc: 0.6120 - val_loss: 1.2470 - val_acc: 0.6200\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.7189 - acc: 0.6315 - val_loss: 1.1937 - val_acc: 0.6000\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 70s 700ms/step - loss: 0.6969 - acc: 0.6170 - val_loss: 1.2135 - val_acc: 0.5890\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 68s 678ms/step - loss: 0.6852 - acc: 0.6310 - val_loss: 1.3441 - val_acc: 0.6190\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.7437 - acc: 0.6170 - val_loss: 1.2461 - val_acc: 0.6210\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.6758 - acc: 0.6270 - val_loss: 1.2089 - val_acc: 0.5790\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.7088 - acc: 0.6105 - val_loss: 1.0978 - val_acc: 0.6110\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.6539 - acc: 0.6270 - val_loss: 1.1170 - val_acc: 0.6060\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 69s 695ms/step - loss: 0.6697 - acc: 0.6370 - val_loss: 1.0910 - val_acc: 0.6010\n"
     ]
    }
   ],
   "source": [
    "h = model1.fit_generator(generator = train_generator,\n",
    "                        # batch_size가 20으로 설정되어 있음\n",
    "                        # 전체 데이터를(2000) 다 읽어오려면 몇 번 돌아가야하는지 설정\n",
    "                       steps_per_epoch = 100,\n",
    "                       epochs = 20,\n",
    "                       validation_data = test_generator,\n",
    "                        # 전체 데이터(1000개)/batch_size\n",
    "                       validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-quantity",
   "metadata": {},
   "source": [
    "##### 전이학습(transfer learning) : 기존의 잘 만들어진 모델을 가져다 쓰는 것\n",
    "- 특성추출: 기존의 모델을 특성추출기로만 사용\n",
    "- 미세조정 : 기존의 모델의 끝 층(dense층에 가까운 층)까지 파라미터를 업데이트 하도록\n",
    "하는 것 (우리 모델과 기존 모델의 유사성을 높이는 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "absent-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 모델을 전이학습\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# weights : imagenet 에 있는 가중치를 사용하겠다\n",
    "#include_top : 분류기(Desne층)도 사용할 것인지 여부\n",
    "# input_shape : 우리 모델의 입력 데이터 크기\n",
    "conv_base = VGG16(weights=\"imagenet\",\n",
    "                 include_top=False,\n",
    "                 input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "charged-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-tobago",
   "metadata": {},
   "source": [
    "#####  VGG16와 우리의 분류기 모델을 연동해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "actual-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = \"./data/dogs_and_cats_small/\"\n",
    "\n",
    "train_dir=os.path.join(base_dir,\"train\")\n",
    "test_dir=os.path.join(base_dir,\"test\")\n",
    "validation_dir=os.path.join(base_dir,\"validation\")\n",
    "\n",
    "dataGen =ImageDataGenerator(rescale=1./255)\n",
    "batch_size=20\n",
    "\n",
    "# VGG16 특성추출기로 데이터를 보내서 특성을 추출하는 함수\n",
    "# extract_features(데이터 폴더의 경로, 데이터의 개수)\n",
    "def extract_features(directory,sample_count) :\n",
    "    # VGG16에 데이터를 보내서 받은 특성과 라벨을 저장하기 위한 변수 설정\n",
    "    features = np.zeros(shape=(sample_count,4,4,512))\n",
    "    #제너레이터에서 생성된 라벨값을 저장\n",
    "    labels=np.zeros(shape=(sample_count))\n",
    "    \n",
    "    #VGG16으로 넘기기 위한 데이터를 제너레이터로 생성\n",
    "    generator=dataGen.flow_from_directory(directory,\n",
    "                                         target_size=(150,150),\n",
    "                                         batch_size=batch_size,\n",
    "                                         class_mode=\"binary\")\n",
    "    \n",
    "    i=0 #VGG16를 호출한 횟수\n",
    "    #제너레이터로부터 데이터와 라벨을 가져온다\n",
    "    for inputs_batch, labels_batch in generator :\n",
    "        #VGG16으로 데이터를 보내서 특성맵을 받아온다\n",
    "        features_batch=conv_base.predict(inputs_batch)\n",
    "        # features 리스트에 batch_size 개수만큼씩 VGG16에서 넘어온 특성을 추가\n",
    "        features[i*batch_size: (i+1)*batch_size]=features_batch\n",
    "        # labels 리스트에 batch_size 개수만큼씩 generator에서 넘어온 label을 추가\n",
    "        labels[i*batch_size: (i+1)*batch_size]=labels_batch\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "        #처리한 데이터 갯수가 전체 데이터 갯수(sample_count)보다 크면\n",
    "        if i*batch_size>=sample_count:\n",
    "            break\n",
    "            \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "likely-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#훈련,테스트,검증 데이터의 특성을 추출\n",
    "train_features,train_labels=extract_features(train_dir,2000)\n",
    "test_features,test_labels=extract_features(test_dir,1000)\n",
    "validation_features,validation_labels=extract_features(validation_dir,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-reserve",
   "metadata": {},
   "source": [
    "##### 우리가 만든 분류기에 VGG16에서 추출된 특성을 넣어주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "twelve-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성맵 데이터를 1차원으로 변환\n",
    "train_features=np.reshape(train_features,(2000,4*4*512))\n",
    "test_features=np.reshape(test_features,(1000,4*4*512))\n",
    "validation_features=np.reshape(validation_features,(1000,4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mounted-thesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,195,329\n",
      "Trainable params: 4,195,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "model3=Sequential()\n",
    "\n",
    "# 은닉층\n",
    "model3.add(Dense(units=512,\n",
    "                 input_dim=4*4*512,\n",
    "                 activation=\"relu\"))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "# 출력층\n",
    "model3.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acquired-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "subject-uncertainty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 1s 419us/sample - loss: 0.5107 - acc: 0.8030 - val_loss: 0.2696 - val_acc: 0.8840\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 0s 211us/sample - loss: 0.2514 - acc: 0.8945 - val_loss: 0.2486 - val_acc: 0.8970\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 0s 202us/sample - loss: 0.1863 - acc: 0.9230 - val_loss: 0.2565 - val_acc: 0.8940\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 0s 202us/sample - loss: 0.1524 - acc: 0.9430 - val_loss: 0.2609 - val_acc: 0.8960\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 0s 202us/sample - loss: 0.1198 - acc: 0.9570 - val_loss: 0.2612 - val_acc: 0.9000\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 0s 180us/sample - loss: 0.1015 - acc: 0.9625 - val_loss: 0.2643 - val_acc: 0.8960\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 0s 188us/sample - loss: 0.0969 - acc: 0.9635 - val_loss: 0.2637 - val_acc: 0.9050\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 0s 204us/sample - loss: 0.0683 - acc: 0.9735 - val_loss: 0.3053 - val_acc: 0.9020\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 0s 214us/sample - loss: 0.0572 - acc: 0.9755 - val_loss: 0.3561 - val_acc: 0.9000\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 0s 195us/sample - loss: 0.0557 - acc: 0.9800 - val_loss: 0.3180 - val_acc: 0.9010\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 0s 210us/sample - loss: 0.0380 - acc: 0.9860 - val_loss: 0.3557 - val_acc: 0.8960\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 0s 206us/sample - loss: 0.0280 - acc: 0.9920 - val_loss: 0.4020 - val_acc: 0.8960\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 0s 198us/sample - loss: 0.0304 - acc: 0.9905 - val_loss: 0.4529 - val_acc: 0.8730\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 0s 187us/sample - loss: 0.0342 - acc: 0.9875 - val_loss: 0.3992 - val_acc: 0.9000\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 0s 207us/sample - loss: 0.0425 - acc: 0.9860 - val_loss: 0.4727 - val_acc: 0.8760\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 0s 183us/sample - loss: 0.0384 - acc: 0.9850 - val_loss: 0.4109 - val_acc: 0.8900\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 0s 201us/sample - loss: 0.0338 - acc: 0.9875 - val_loss: 0.5057 - val_acc: 0.8720\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 0s 215us/sample - loss: 0.0222 - acc: 0.9910 - val_loss: 0.4598 - val_acc: 0.8780\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 0s 215us/sample - loss: 0.0262 - acc: 0.9915 - val_loss: 0.4241 - val_acc: 0.8980\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 0s 224us/sample - loss: 0.0246 - acc: 0.9905 - val_loss: 0.4818 - val_acc: 0.9020\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 0s 206us/sample - loss: 0.0291 - acc: 0.9895 - val_loss: 0.4275 - val_acc: 0.8930\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 0s 202us/sample - loss: 0.0274 - acc: 0.9885 - val_loss: 0.4613 - val_acc: 0.8940\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 0s 201us/sample - loss: 0.0175 - acc: 0.9940 - val_loss: 0.4553 - val_acc: 0.8920\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 0s 206us/sample - loss: 0.0094 - acc: 0.9975 - val_loss: 0.5644 - val_acc: 0.8960\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 0s 206us/sample - loss: 0.0129 - acc: 0.9965 - val_loss: 0.4815 - val_acc: 0.8950\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 0s 189us/sample - loss: 0.0374 - acc: 0.9855 - val_loss: 0.4696 - val_acc: 0.9020\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 0s 187us/sample - loss: 0.0322 - acc: 0.9880 - val_loss: 0.4306 - val_acc: 0.8890\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 0s 201us/sample - loss: 0.0157 - acc: 0.9965 - val_loss: 0.4525 - val_acc: 0.8940\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 0s 173us/sample - loss: 0.0145 - acc: 0.9960 - val_loss: 0.5793 - val_acc: 0.8840\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 0s 203us/sample - loss: 0.0143 - acc: 0.9950 - val_loss: 0.5872 - val_acc: 0.8880\n"
     ]
    }
   ],
   "source": [
    "h3=model3.fit(train_features,train_labels,\n",
    "                      batch_size=20,\n",
    "                     epochs=30,\n",
    "                     validation_data=(test_features,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dependent-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2582607d080>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=h3.history[\"acc\"]\n",
    "val_acc=h3.history[\"val_acc\"]\n",
    "\n",
    "epochs=np.arange(len(acc))\n",
    "\n",
    "plt.plot(epochs,acc,c=\"red\",label=\"Train\")\n",
    "plt.plot(epochs,val_acc,c=\"pink\",label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "golden-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 18,910,017\n",
      "Trainable params: 18,910,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "# 우리가 만든 모델에 VGG16을 끼워넣기\n",
    "\n",
    "model4.add(conv_base)\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(512,activation=\"relu\"))\n",
    "model4.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-purple",
   "metadata": {},
   "source": [
    "#####  동결  \n",
    "기존의 모델을 우리 모델에 삽입을 하면 오차 역전파 시 기존 모델의 파라미터 값도 갱신이\n",
    "되어 많은 데이터로 학습된 기존 모델의 장점이 사라져 버림 -> 기존 모델의 파라미터가 갱신이 되지 않도록\n",
    "막는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ethical-practice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# 동결 되기 전 훈련되는 vgg16 가중치 수\n",
    "print(len(model4.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adjacent-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16의 전체 층에 대해 동결\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "automotive-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 동결 후의 훈련되는 VGG16의 가중치 수\n",
    "print(len(model4.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "organizational-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 증식 설정\n",
    "train_dataGen = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=20,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode=\"nearest\")\n",
    "\n",
    "test_dataGen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_dataGen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode=\"binary\")\n",
    "test_generator = test_dataGen.flow_from_directory(test_dir,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ancient-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "comic-techno",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-36-c597a5ecc7bf>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.5210 - acc: 0.8005 - val_loss: 0.2530 - val_acc: 0.8920\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.3128 - acc: 0.8605 - val_loss: 0.3664 - val_acc: 0.8440\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.2588 - acc: 0.8900 - val_loss: 0.2629 - val_acc: 0.8950\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.2581 - acc: 0.8940 - val_loss: 0.4219 - val_acc: 0.8340\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.2448 - acc: 0.8965 - val_loss: 0.2490 - val_acc: 0.9020\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.2186 - acc: 0.9095 - val_loss: 0.2419 - val_acc: 0.9050\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 0.2043 - acc: 0.9120 - val_loss: 0.2415 - val_acc: 0.9070\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.1952 - acc: 0.9135 - val_loss: 0.2495 - val_acc: 0.9030\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.2101 - acc: 0.9080 - val_loss: 0.2552 - val_acc: 0.9010\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.1776 - acc: 0.9255 - val_loss: 0.2641 - val_acc: 0.9030\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.2067 - acc: 0.9170 - val_loss: 0.2495 - val_acc: 0.9040\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.1496 - acc: 0.9385 - val_loss: 0.2814 - val_acc: 0.9020\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.1550 - acc: 0.9360 - val_loss: 0.3028 - val_acc: 0.8880\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.1737 - acc: 0.9265 - val_loss: 0.2608 - val_acc: 0.9020\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.1492 - acc: 0.9430 - val_loss: 0.2889 - val_acc: 0.8950\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.1474 - acc: 0.9385 - val_loss: 0.2665 - val_acc: 0.8980\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.1419 - acc: 0.9405 - val_loss: 0.2743 - val_acc: 0.9050\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.1337 - acc: 0.9420 - val_loss: 0.2935 - val_acc: 0.8980\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.1434 - acc: 0.9440 - val_loss: 0.2835 - val_acc: 0.9030\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.1529 - acc: 0.9405 - val_loss: 0.3500 - val_acc: 0.8830\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.1306 - acc: 0.9500 - val_loss: 0.3156 - val_acc: 0.8840\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.1247 - acc: 0.9480 - val_loss: 0.2866 - val_acc: 0.8970\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.1154 - acc: 0.9510 - val_loss: 0.2736 - val_acc: 0.8930\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.1194 - acc: 0.9555 - val_loss: 0.3539 - val_acc: 0.8960\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.1434 - acc: 0.9365 - val_loss: 0.2632 - val_acc: 0.9020\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.1199 - acc: 0.9555 - val_loss: 0.2820 - val_acc: 0.8960\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.1186 - acc: 0.9550 - val_loss: 0.2789 - val_acc: 0.9040\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.1085 - acc: 0.9580 - val_loss: 0.2797 - val_acc: 0.9050\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.0904 - acc: 0.9660 - val_loss: 0.3249 - val_acc: 0.8970\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.0946 - acc: 0.9620 - val_loss: 0.3375 - val_acc: 0.9020\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.0949 - acc: 0.9630 - val_loss: 0.3465 - val_acc: 0.9030\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.0992 - acc: 0.9635 - val_loss: 0.3344 - val_acc: 0.9010\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.0964 - acc: 0.9630 - val_loss: 0.3491 - val_acc: 0.8980\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.0796 - acc: 0.9685 - val_loss: 0.3193 - val_acc: 0.8940\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.1069 - acc: 0.9595 - val_loss: 0.3629 - val_acc: 0.8780\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.0858 - acc: 0.9670 - val_loss: 0.3276 - val_acc: 0.9000\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.0885 - acc: 0.9645 - val_loss: 0.3374 - val_acc: 0.9000\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.0641 - acc: 0.9755 - val_loss: 0.3600 - val_acc: 0.9050\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.0897 - acc: 0.9655 - val_loss: 0.3297 - val_acc: 0.8980\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.0757 - acc: 0.9700 - val_loss: 0.3308 - val_acc: 0.9080\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.0833 - acc: 0.9675 - val_loss: 0.3411 - val_acc: 0.9000\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.0582 - acc: 0.9740 - val_loss: 0.3448 - val_acc: 0.8970\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.0567 - acc: 0.9790 - val_loss: 0.3664 - val_acc: 0.8930\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 0.0711 - acc: 0.9735 - val_loss: 0.4417 - val_acc: 0.8850\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.0588 - acc: 0.9770 - val_loss: 0.4102 - val_acc: 0.8900\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.0602 - acc: 0.9770 - val_loss: 0.3412 - val_acc: 0.9030\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.0588 - acc: 0.9780 - val_loss: 0.3431 - val_acc: 0.8960\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.0655 - acc: 0.9785 - val_loss: 0.3461 - val_acc: 0.8970\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 0.0632 - acc: 0.9755 - val_loss: 0.3918 - val_acc: 0.8920\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.0593 - acc: 0.9775 - val_loss: 0.3629 - val_acc: 0.9030\n"
     ]
    }
   ],
   "source": [
    "h4 = model4.fit_generator(generator=train_generator,\n",
    "                         steps_per_epoch=100,\n",
    "                         epochs=50,\n",
    "                         validation_data=test_generator,\n",
    "                         validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-external",
   "metadata": {},
   "source": [
    "#####  미세조정\n",
    "- 기존의 모델과 우리 모델이 잘 연결되도록 기존 모델의 아래층까지 학습이 가능하도록 만들어 주는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "compliant-compound",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# block5_conv1 층 까지만 학습이 되도록 미세 조정\n",
    "# 학습이 되는 층 -> block5_conv1,block5_conv2,block5_conv2,block5_conv3,block5_conv4,block5_conv5,block5_pool\n",
    "\n",
    "#VGG16 모델 전체가 학습이 되도록 설정\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "\n",
    "# VGG16의 신경망층 한층을 가져온다\n",
    "for layer in conv_base.layers :\n",
    "    #가져온 층의 이름이  block5_conv1 이라면\n",
    "    if layer.name == \"block5_conv1\":\n",
    "        set_trainable = True\n",
    "    if set_trainable == True:\n",
    "        layer.trainable = True\n",
    "    else :\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "distinguished-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=\"adam\",\n",
    "               metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "british-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 3.0223 - acc: 0.5100 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6933 - acc: 0.4790 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4900 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4920 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.6932 - acc: 0.4860 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 0.6932 - acc: 0.4760 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4930 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6932 - acc: 0.4880 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.6932 - acc: 0.4900 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6932 - acc: 0.4810 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.6932 - acc: 0.4830 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4800 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6932 - acc: 0.4830 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6932 - acc: 0.4840 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6932 - acc: 0.4890 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4940 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4930 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4850 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4910 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4860 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4930 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4850 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.6932 - acc: 0.4900 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4920 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4940 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4960 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "h4 = model4.fit_generator(generator=train_generator,\n",
    "                         steps_per_epoch=100,\n",
    "                         epochs=50,\n",
    "                         validation_data=test_generator,\n",
    "                         validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "positive-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2582c59eba8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=h4.history[\"acc\"]\n",
    "val_acc=h4.history[\"val_acc\"]\n",
    "\n",
    "epochs=np.arange(len(acc))\n",
    "\n",
    "plt.plot(epochs,acc,c=\"red\",label=\"Train\")\n",
    "plt.plot(epochs,val_acc,c=\"pink\",label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-california",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
